{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#math and linear algebra stuff\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "#plots\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "#mpl.rc('text', usetex = True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving least absolute deviation with positivity constraint using Chambolle Pock\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook has been designed after reading an article from Camille Sutour about noise estimation in images (Noise level function).\n",
    "In this work, she tries to estimate the NLF (noise level function) with a 2 order polynomial, with non-negative coefficient, hence the positivity constraint.\n",
    "\n",
    "In order to make the estimator more robust to outliers, she uses as least absolute deviation instead of the classical least square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The usecase: Noise model estimation\n",
    "\n",
    "After a specific routine has been used, we assume that pure noise patches have been found in an image.\n",
    "\n",
    "One can assume locally stationary noise behaviour, can then compute for each patch its mean $\\mu=\\frac{1}{N} \\sum_{i=0}^{N-1} x_i$ and the unbiased estimator of variance $\\sigma^2=\\frac{1}{N-1} \\sum_{i=0}^{N-1} (x_i-\\mu)^2$.\n",
    "\n",
    "Given a list of pairs $\\left( \\hat{\\mu_p}, \\hat{\\sigma_p}^2 \\right)$, one is now interested in knowing the Noise Level Function (NLF), which is a $\\mathbb{R} \\rightarrow \\mathbb{R}^+$ function, that gives the noise variance for a fiven level of image intensity.\n",
    "\n",
    "The author assumes that the NLF is a positively increasing second order polynomial of the image intensity. Then one just performs a least square on the following problem:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\underset{x\\in\\mathbb{R}^3}{\\text{min}} \\qquad ||Ax-b||_2^2\n",
    "\\end{align*}\n",
    "\n",
    "Where we have:\n",
    "\n",
    "* $A=\\begin{pmatrix} \\mu_0^2 & \\mu_0 & 1\\\\\n",
    "\\mu_1^2 & \\mu_1 & 1\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "\\mu_{N-1}^2 & \\mu_{N-1} & 1\\end{pmatrix}$\n",
    "\n",
    "* $b=\\begin{pmatrix}\\sigma_0^2\\\\ \\sigma_1^2 \\\\ \\vdots \\\\ \\sigma_{N-1}^2\\end{pmatrix}$\n",
    "\n",
    "The solution vector $\\hat{x}$ is given by Moore-Penrose pseudo-inverse: $A^+ b$ where $A^+=(A^T A)^{-1} A^T$\n",
    "However, the author prefers to use the least absolute deviation, with positivity constraint:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\underset{x\\in\\mathbb{R}^{+3}}{\\text{min}} \\qquad ||Ax-b||_1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying the problem under the CP framework\n",
    "\n",
    "### First overview of CP mapping\n",
    "First of all, one can notice that the constrained optimization problem can be recasted as a non explicitly constrained optimization problem, just by adding a term featuring the convex indicator function of the non-negative orthant in $\\mathbb{R}^3$:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\delta_{\\mathbb{R}^{3+}}(x) &= \n",
    "    \\begin{cases}0 \\qquad &\\text{if } x \\in \\mathbb{R}^{3+} \\\\\n",
    "    +\\infty & \\text{otherwise} \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "Such that we can write the new optimization problem:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\underset{x}{\\text{min}} \\quad ||Ax-b||_1 + \\delta_{\\mathbb{R}^{3+}}(x)\n",
    "\\end{align*}\n",
    "\n",
    "We can now try to map this problem to the Chambolle pock pattern:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\underset{x}{min} \\quad f(x) + g(Lx)\n",
    "\\end{align*}\n",
    "where $f$ and $g$ are convex functions, whose proximity operators can be computed, and $L$\n",
    "is a linear operator.\n",
    "\n",
    "and its dual problem:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\underset{u}{min} \\quad f^*(-L^*u) + g^*(u)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Recalling principle of CP algorithm\n",
    "\n",
    "The Chambolle-Pock algorithm takes initial estimates $x^{(0)}$ and $u^{(0)}$ of the primal and dual solutions, a parameter $\\tau>0$, a second parameter $\\sigma>0$ such that $\\sigma \\tau \\|L\\|^2 < 1$, and a relaxation parameter $0<\\rho<2$, and iterates, for $k=1,2,\\ldots$:\n",
    "  \n",
    "\\begin{align*}\n",
    "    u^{k} &= \\mathrm{prox}_{\\sigma g^*}( u^{k-1} + \\sigma L(\\tilde{x}^{k-1}) \\\\\n",
    "    x^{k} &= \\mathrm{prox}_{\\tau f}(  x^{k-1}-\\tau L^* u^{k} ) \\\\\n",
    "    \\tilde{x}^{k} &= x^{k} + \\rho (x^{k}-x^{k-1})\\\\\n",
    "\\end{align*}\n",
    "  \n",
    "Where, $x^{(k)}$ converges to a primal solution $x^\\star$ and $u^{(k)}$ converges to a dual solution $u^\\star$.\n",
    "\n",
    "We recall that being able to compute the proximity operator of $f^*$ is equivalent to being able to compute the proximity operator of $f$, thanks to the Moreau identity:\n",
    "  \n",
    "\\begin{equation}\n",
    "    x = \\mathrm{prox}_{\\gamma f^*}(x) + \\gamma \\mathrm{prox}_{\\frac{f}{\\gamma}}\\left(\\frac{x}{\\gamma}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying the $g$ part\n",
    "\n",
    "We recall that the proximal operator for the convex indicator $\\delta_{\\mathbb{R}^{3+}}$ is simply the projection operator onto the non-negative orthant $\\mathbb{R}^{3+}$:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{prox}_{\\delta_{\\mathbb{R}^{3+}}}(x_n) = \\max \\left( 0, x_n \\right)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying the $f$ part\n",
    "\n",
    "We recall that the proximal operator of the $\\ell^1$ norm is soft thresholding:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{prox}_{\\gamma ||\\cdot||_1}(x_n) = \\max \\left( 0, 1-\\frac{\\gamma}{|x_n|} \\right) x_n\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
